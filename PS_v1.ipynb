{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import fitz  \n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get arXiv Paper URLs\n",
    "def get_arxiv_paper_urls(query, max_results=10):\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    \n",
    "    paper_urls = []\n",
    "    for entry in root.findall(\"{http://www.w3.org/2005/Atom}entry\"):\n",
    "        paper_url = entry.find(\"{http://www.w3.org/2005/Atom}id\").text\n",
    "        paper_urls.append(paper_url)\n",
    "    \n",
    "    return paper_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract Paper Metadata\n",
    "def extract_paper_content(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    title_tag = soup.find(\"meta\", {\"name\": \"citation_title\"})\n",
    "    title = title_tag[\"content\"] if title_tag else \"Title not found\"\n",
    "    \n",
    "    abstract_tag = soup.find(\"blockquote\", {\"class\": \"abstract\"})\n",
    "    abstract_text = abstract_tag.text.replace(\"Abstract: \", \"\").strip() if abstract_tag else \"Abstract not found\"\n",
    "    \n",
    "    pdf_url = url.replace(\"abs\", \"pdf\") + \".pdf\"\n",
    "    \n",
    "    return {\"title\": title, \"abstract\": abstract_text, \"pdf_url\": pdf_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Download and Extract PDF\n",
    "def download_and_extract_pdf(pdf_url):\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_filename = pdf_url.split(\"/\")[-1]\n",
    "    with open(pdf_filename, \"wb\") as pdf_file:\n",
    "        pdf_file.write(response.content)\n",
    "    \n",
    "    doc = fitz.open(pdf_filename)\n",
    "    full_text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        full_text += page.get_text(\"text\")\n",
    "    doc.close()\n",
    "    \n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Combine extracted PDF content with the vectorization pipeline\n",
    "# def process_papers_and_add_to_rag(query, max_results=5):\n",
    "#     # Fetch arXiv paper URLs based on query\n",
    "#     urls = get_arxiv_paper_urls(query, max_results=max_results)\n",
    "    \n",
    "#     # Initialize a list to store documents\n",
    "#     docs = []\n",
    "    \n",
    "#     # Extract content and download each paper\n",
    "#     for url in urls:\n",
    "#         content = extract_paper_content(url)\n",
    "#         print(f\"Processing: {content['title']}\")\n",
    "        \n",
    "#         # Download and extract full paper content (PDF)\n",
    "#         full_content = download_and_extract_pdf(content[\"pdf_url\"])\n",
    "#         print(f\"Downloaded and extracted paper content, length: {len(full_content)}\")\n",
    "        \n",
    "#         # Store title and content in a dictionary for processing\n",
    "#         docs.append({\"title\": content[\"title\"], \"page_content\": full_content})\n",
    "    \n",
    "#     # Step 5: Prepare the documents for embedding and chunking\n",
    "#     # Convert to the format needed for text splitting and embedding\n",
    "#     formatted_docs = [{\"page_content\": doc[\"page_content\"], \"metadata\": {\"title\": doc[\"title\"]}} for doc in docs]\n",
    "    \n",
    "#     # Use RecursiveCharacterTextSplitter to chunk the document content\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "#     splits = text_splitter.split_documents(formatted_docs)\n",
    "    \n",
    "#     # Step 6: Embedding model and vectorstore setup\n",
    "#     embed = OllamaEmbeddings(model=\"all-minilm\")\n",
    "#     vectorstore = Chroma.from_documents(documents=splits, embedding=embed)\n",
    "    \n",
    "#     # Step 7: RAG Chain setup\n",
    "#     retriever = vectorstore.as_retriever()\n",
    "#     prompt = load_prompt(\"rlm/rag-prompt\")  # Load the RAG prompt from a source or file\n",
    "#     llm = ChatOllama()  # Load your chosen language model here\n",
    "\n",
    "#     def format_docs(docs):\n",
    "#         return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#     # Define the RAG chain\n",
    "#     rag_chain = (\n",
    "#         {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "#         | prompt\n",
    "#         | llm\n",
    "#         | StrOutputParser()\n",
    "#     )\n",
    "\n",
    "#     return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Lecture Notes: Neural Network Architectures\n",
      "Downloaded and extracted paper content, length: 95012\n",
      "Processing: Self-Organizing Multilayered Neural Networks of Optimal Complexity\n",
      "Downloaded and extracted paper content, length: 22593\n",
      "Processing: Neural Network Processing Neural Networks: An efficient way to learn higher order functions\n",
      "Downloaded and extracted paper content, length: 7378\n",
      "Based on the academic paper \"Neural Network Processing Neural Networks: An Efficient Way to Learn Higher Order Functions\" by Firat Tuna, the latest advances in neural networks include:\n",
      "\n",
      "1. Neural Network Processing Neural Networks (NNPNNs): This is a new class of neural networks that can process and represent rich structures, such as functions, more eflectively than traditional neural networks. NNPNNs input neural networks and numerical values instead of just numerical values, enabling them to reason with these structures more effectively.\n",
      "2. HyperNetworks: This is a recent development in the field of neural networks that enables the learning of higher-order functions by using a hierarchical structure of neural networks. HyperNetworks were introduced in the paper \"HyperNetworks\" by David Ha, Andrew Dai, and Quoc V. Le.\n",
      "3. Mini-batch gradient descent: This is an optimization algorithm commonly used in training neural networks. The paper \"Neural Networks for Machine Learning - Lecture 6a - Overview of mini-batch gradient descent\" by Geoffrey Hinton provides an overview of this algorithm and its applications in neural network training.\n",
      "4. Approximation capabilities of multilayer feedforward networks: This is a topic explored in the paper \"Approximation Capabilities of Multilayer Feedforward Networks\" by Kurt Hornik. The paper discusses the approximation capabilities of multilayer feedforward networks and their implications for neural network design.\n",
      "\n",
      "These advances in neural networks demonstrate the ongoing research and development in the field, as well as the potential for new and innovative approaches to improve the performance and capabilities of neural networks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def process_papers_and_add_to_rag(query, max_results=5):\n",
    "    # Fetch arXiv paper URLs based on query\n",
    "    urls = get_arxiv_paper_urls(query, max_results=max_results)\n",
    "    \n",
    "    # Initialize a list to store documents\n",
    "    docs = []\n",
    "    \n",
    "    # Extract content and download each paper\n",
    "    for url in urls:\n",
    "        content = extract_paper_content(url)\n",
    "        print(f\"Processing: {content['title']}\")\n",
    "        \n",
    "        # Download and extract full paper content (PDF)\n",
    "        full_content = download_and_extract_pdf(content[\"pdf_url\"])\n",
    "        print(f\"Downloaded and extracted paper content, length: {len(full_content)}\")\n",
    "        \n",
    "        # Store title and content in a dictionary for processing\n",
    "        docs.append({\"title\": content[\"title\"], \"page_content\": full_content})\n",
    "    \n",
    "    # Step 5: Prepare the documents for embedding and chunking\n",
    "    # Convert docs into a list of `Document` objects\n",
    "    formatted_docs = [\n",
    "        Document(page_content=doc[\"page_content\"], metadata={\"title\": doc[\"title\"]}) for doc in docs\n",
    "    ]\n",
    "    \n",
    "    # Use RecursiveCharacterTextSplitter to chunk the document content\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(formatted_docs)\n",
    "    \n",
    "    # Step 6: Embedding model and vectorstore setup\n",
    "    embed = OllamaEmbeddings(model=\"all-minilm\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embed)\n",
    "    \n",
    "    # Step 7: RAG Chain setup\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    # prompt = load_prompt(\"rlm/rag-prompt\")  # Load the RAG prompt from a source or file\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an expert in academic research. Answer questions based on the following academic paper context.\",\n",
    "            ),\n",
    "            (\"user\", \"Here is the academic context: {context}\"),\n",
    "            (\"user\", \"Now answer the following question: {question}\"),\n",
    "            # MessagesPlaceholder(variable_name=\"messages\"),  # Placeholder for additional user messages\n",
    "        ]\n",
    "    )\n",
    "    llm = ChatOllama()  # Load your chosen language model here\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Define the RAG chain\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # Example query to the RAG chain\n",
    "    result = rag_chain.invoke(\"What are the latest advances in neural networks?\")\n",
    "    print(result)\n",
    "\n",
    "# Example: Use the function to process papers related to \"neural networks\"\n",
    "process_papers_and_add_to_rag(query=\"neural networks\", max_results=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Lecture Notes: Neural Network Architectures\n",
      "Downloaded and extracted paper content, length: 95012\n",
      "Processing: Self-Organizing Multilayered Neural Networks of Optimal Complexity\n",
      "Downloaded and extracted paper content, length: 22593\n",
      "Processing: Neural Network Processing Neural Networks: An efficient way to learn higher order functions\n",
      "Downloaded and extracted paper content, length: 7378\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Use the function to process papers related to \"neural networks\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_papers_and_add_to_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneural networks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m, in \u001b[0;36mprocess_papers_and_add_to_rag\u001b[1;34m(query, max_results)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Use RecursiveCharacterTextSplitter to chunk the document content\u001b[39;00m\n\u001b[0;32m     26\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m splits \u001b[38;5;241m=\u001b[39m \u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Step 6: Embedding model and vectorstore setup\u001b[39;00m\n\u001b[0;32m     30\u001b[0m embed \u001b[38;5;241m=\u001b[39m OllamaEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-minilm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_text_splitters\\base.py:94\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m     92\u001b[0m texts, metadatas \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 94\u001b[0m     texts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m)\n\u001b[0;32m     95\u001b[0m     metadatas\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# Example: Use the function to process papers related to \"neural networks\"\n",
    "# rag_chain = process_papers_and_add_to_rag(query=\"neural networks\", max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
